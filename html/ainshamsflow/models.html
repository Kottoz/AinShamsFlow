<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ainshamsflow.models API documentation</title>
<meta name="description" content="Models Module â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ainshamsflow.models</code></h1>
</header>
<section id="section-intro">
<p>Models Module.</p>
<p>In this module we define the Sequential model type, which is the
main model type in asf.
We may implement more model types in the future.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Models Module.

In this module we define the Sequential model type, which is the
main model type in asf.
We may implement more model types in the future.
&#34;&#34;&#34;

import shelve
from os.path import join as join_path
import numpy as np

import ainshamsflow.layers as _layers
import ainshamsflow.optimizers as optimizers
import ainshamsflow.losses as losses
import ainshamsflow.metrics as _metrics
import ainshamsflow.regularizers as regularizers
from ainshamsflow.data import Dataset
from ainshamsflow.utils.utils import get_dataset_from_xy
from ainshamsflow.utils.asf_errors import (UncompiledModelError, MultipleAccessError, BaseClassError,
                                                                                   LayerNotFoundError, UnsupportedShapeError, WrongObjectError,
                                                                                   InvalidShapeError)


__pdoc__ = dict()

__pdoc__[&#39;Model.evaluate&#39;] = False
__pdoc__[&#39;Model.fit&#39;] = False
__pdoc__[&#39;Model.get_layer&#39;] = False
__pdoc__[&#39;Model.load_weights&#39;] = False
__pdoc__[&#39;Model.pop_layer&#39;] = False
__pdoc__[&#39;Model.add_layer&#39;] = False
__pdoc__[&#39;Model.get_layer&#39;] = False
__pdoc__[&#39;Model.load_weights&#39;] = False
__pdoc__[&#39;Model.save_weights&#39;] = False
__pdoc__[&#39;Model.print_summary&#39;] = False

__pdoc__[&#39;Sequential.diff&#39;] = False
__pdoc__[&#39;Sequential.add_input_shape_to_layers&#39;] = False
__pdoc__[&#39;Sequential.set_weights&#39;] = False
__pdoc__[&#39;Sequential.get_weights&#39;] = False


def load_model(filename):
        &#34;&#34;&#34;Loads a model saved in &#39;filename&#39;.&#34;&#34;&#34;

        with shelve.open(filename) as db:
                model = db[&#39;self&#39;]
        return model


class Model(_layers.Layer):
        &#34;&#34;&#34;Models Base Class.&#34;&#34;&#34;

        def __init__(self, input_shape, name, trainable=True):
                &#34;&#34;&#34;
                Args:
                        input_shape: tuple showing the shape of the input to the model.
                        name: Name of the model.
                        trainable: Boolean to define whether this model is trainable or not.
                &#34;&#34;&#34;

                if not isinstance(input_shape, tuple):
                        raise WrongObjectError(input_shape, tuple())
                if len(input_shape) &lt;= 0:
                        raise InvalidShapeError(input_shape)
                for ch in input_shape:
                        if ch &lt;= 0:
                                raise InvalidShapeError(input_shape)

                super().__init__(name, trainable)
                self.n_in = input_shape
                self.n_out = None
                self.input_shape = &#39;(None&#39; + (&#39;,{:4}&#39;*len(self.n_in)).format(*self.n_in) + &#39;)&#39;
                self.output_shape = None

                self.optimizer = None
                self.loss = None
                self.metrics = None
                self.regularizer = None

        def compile(self, optimizer, loss, metrics=None, regularizer=None):
                &#34;&#34;&#34;Define model optimizer, loss function , metrics and regularizer.

                All arguments can be either an instance of the required class,
                or a string for a class that exists in the framework.

                Args:
                        optimizer: the optimizer used for training.
                        loss: loss function used for training.
                        metrics: a list of metrics (and/or losses) used to monitor training progress.
                        regularizer: regularizer used during training.
                &#34;&#34;&#34;
                if isinstance(optimizer, str):
                        optimizer = optimizers.get(optimizer)
                if not isinstance(optimizer, optimizers.Optimizer):
                        raise WrongObjectError(optimizer, optimizers.Optimizer())

                if isinstance(loss, str):
                        loss = losses.get(loss)
                if not isinstance(loss, losses.Loss):
                        raise WrongObjectError(loss, losses.Loss())

                if metrics:
                        if not isinstance(metrics, list):
                                raise WrongObjectError(metrics, list())
                        for i in range(len(metrics)):
                                if isinstance(metrics[i], str):
                                        metrics[i] = _metrics.get(metrics[i])
                                if not isinstance(metrics[i], _metrics.Metric):
                                        raise WrongObjectError(metrics[i], _metrics.Metric())
                else:
                        metrics = []

                if regularizer is not None:
                        if isinstance(regularizer, str):
                                regularizer = regularizers.get(regularizer)
                        if not isinstance(regularizer, regularizers.Regularizer):
                                raise WrongObjectError(regularizer, regularizers.Regularizer())


                self.optimizer = optimizer
                self.loss = loss
                self.metrics = metrics
                self.regularizer = regularizer

        def evaluate(self, x, y, batch_size):
                raise BaseClassError

        def fit(self, x, y, epochs, batch_size):
                raise BaseClassError

        def predict(self, x):
                &#34;&#34;&#34;Predict new data.

                Args:
                        x: input data to be passed through the model.
                &#34;&#34;&#34;

                if isinstance(x, Dataset):
                        x = x.data

                return self.__call__(x)

        def add_layer(self, layer):
                raise BaseClassError

        def get_layer(self, layer_name, index):
                raise BaseClassError

        def pop_layer(self):
                raise BaseClassError

        def load_weights(self, filepath):
                raise BaseClassError

        def save_weights(self, filepath):
                raise BaseClassError

        def save_model(self, filename):
                &#34;&#34;&#34;Saves model by its name in the directory specified.&#34;&#34;&#34;

                with shelve.open(filename) as db:
                        db[&#39;self&#39;] = self

        def print_summary(self):
                raise BaseClassError


class Sequential(Model):
        &#34;&#34;&#34;Sequential Model Class.
        Used to create Models where there is a strict, linear, layer-by-layer
        structure.
        &#34;&#34;&#34;

        __name__ = &#39;Seq. Model&#39;

        def __init__(self, layers, input_shape, name=None):
                &#34;&#34;&#34;
                Args:
                        layers: list of layers in order of data path.
                                must be a list of layer objects.
                        input_shape: tuple showing the shape of the input to the model.
                        name: name of the model.
                &#34;&#34;&#34;

                if not isinstance(layers, list):
                        raise WrongObjectError(layers, list())
                for layer in layers:
                        if not isinstance(layer, _layers.Layer):
                                raise WrongObjectError(layer, _layers.Layer())
                if not isinstance(input_shape, tuple):
                        raise WrongObjectError(input_shape, tuple())

                super().__init__(input_shape, name)
                self.layers = layers

                for layer in self.layers:
                        input_shape = layer.add_input_shape_to_layers(input_shape)

                self.n_out = self.layers[-1].n_out
                n_out = [str(ch) for ch in self.n_out]
                self.output_shape = &#39;(None&#39; + (&#39;,{:4}&#39;*len(n_out)).format(*n_out) + &#39;)&#39;

        def fit(self, x, y=None, epochs=1, batch_size=None, verbose=True, shuffle=True,
                        valid_split=None, valid_data=None, valid_batch_size=None):
                &#34;&#34;&#34;Fit the model to the training data.

                Args:
                        x: Either an Array of data features. must be of the same shape as the model&#39;s
                                `input_shape`.
                                __OR__ a dataset object that may include the data and labels for training.

                        y: This is the array of data labels.
                                Only used if `x` doesn&#39;t have the labels included in the dataset object.

                        epochs: number of rounds gone through the training set during training.

                        batch_size: size of the mini-batch used during training:
                                `None` =&gt; batch training,
                                `1` =&gt; online training,
                                other int =&gt; mini-batch training.

                        verbose: Whether to print training data or not during training.

                        shuffle: Whether to shuffle the training data before training.

                        valid_split: how much to split the training set to get a new validation set.
                                (0 &lt; `valid_split` &lt; 1)
                                Valid only if `valid_data` is `None`

                        valid_data: The validation set used in showing the training statistics.
                                Either a tuple: (`x_valid`, `y_valid`) __OR__ a dataset object with data
                                features and labels included.

                        valid_batch_size: size of the mini-batch used during evaluation of the
                                validation set:
                                `None` =&gt; batch training,
                                `1` =&gt; online training,
                                other int =&gt; mini-batch training.

                Returns:
                        history: history object used to plot the training statistics.
                                you can plot the learning curves by using:

                ```python
                &gt;&gt;&gt; history = model.fit(...)
                &gt;&gt;&gt; history.show()
                ```
                &#34;&#34;&#34;

                if self.optimizer is None:
                        raise UncompiledModelError

                ds_train = get_dataset_from_xy(x, y)

                if valid_data is not None:
                        if isinstance(valid_data, tuple):
                                ds_valid = get_dataset_from_xy(*valid_data)
                        else:
                                ds_valid = get_dataset_from_xy(valid_data, None)
                elif valid_split is not None:
                        ds_train, ds_valid = ds_train.split(valid_split)
                else:
                        ds_valid = None

                if shuffle:
                        ds_train.shuffle()

                return self.optimizer(ds_train, ds_valid, epochs, batch_size, valid_batch_size, self.layers,
                                                          self.loss, self.metrics, self.regularizer, verbose=verbose, training=True)

        def evaluate(self, x, y=None, batch_size=None, verbose=True):
                &#34;&#34;&#34;Evaluate the model on validation data.

                Args:
                        x: Either an Array of data features. must be of the same shape as the model&#39;s
                                `input_shape`.
                                __OR__ a dataset object that may include the data and labels for training.

                        y: This is the array of data labels.
                                Only used if `x` doesn&#39;t have the labels included in the dataset object.

                        batch_size: size of the mini-batch used during evaluation:
                                `None` =&gt; batch evaluation,
                                `1` =&gt; online evaluation,
                                other int =&gt; mini-batch evaluation.

                        verbose: Whether to print the evaluation data or return it.

                Returns:
                        None: if `verbose` = `True` __OR__
                        loss_value: value of the loss function.
                        metric_values: list of the metric values for all metrics.

                &#34;&#34;&#34;

                ds = get_dataset_from_xy(x, y)

                if self.optimizer is None:
                        raise UncompiledModelError
                return self.optimizer(ds, None,  1, batch_size, None, self.layers, self.loss, self.metrics, self.regularizer,
                                                                 verbose=verbose, training=False)

        def add_layer(self, layer):
                &#34;&#34;&#34;Add a new layer to the network.&#34;&#34;&#34;

                if not isinstance(layer, _layers.Layer):
                        raise WrongObjectError(layer, _layers.Layer())

                if self.layers:
                        n_out = self.layers[-1].n_out
                else:
                        n_out = self.n_in
                self.layers.append(layer)
                layer.add_input_shape_to_layer(n_out)

        def get_layer(self, *, index=None, layer_name=None):
                &#34;&#34;&#34;Get a specific layer from the model.

                You can either access the layer using it&#39;s name __xor__ it&#39;s index.
                &#34;&#34;&#34;

                if (index is None) ^ (layer_name is None):
                        if not isinstance(index, int):
                                raise WrongObjectError(index, 1)
                        if not isinstance(layer_name, str):
                                raise WrongObjectError(layer_name, &#39;&#39;)

                        if index is None:
                                for layer in self.layers:
                                        if layer.name == layer_name:
                                                return layer
                                raise LayerNotFoundError(&#39;name&#39;, layer_name)
                        elif index &lt; len(self.layers):
                                return self.layers[index]
                        else:
                                raise LayerNotFoundError(&#39;id&#39;, index)
                else:
                        raise MultipleAccessError

        def pop_layer(self):
                &#34;&#34;&#34;Pop the last layer from the model.&#34;&#34;&#34;

                if self.layers:
                        self.layers.pop()

        def load_weights(self, filepath):
                &#34;&#34;&#34;Load weights from a directory.&#34;&#34;&#34;

                with shelve.open(join_path(filepath, self.name+&#39;_weights&#39;)) as db:
                        for i in range(len(self.layers)):
                                layer_name = &#39;layer{:03d}&#39;.format(i)
                                self.layers[i] = db[layer_name]

        def save_weights(self, filepath):
                &#34;&#34;&#34;Save weights to a directory.&#34;&#34;&#34;

                with shelve.open(join_path(filepath, self.name+&#39;_weights&#39;)) as db:
                        for i, layer in enumerate(self.layers):
                                layer_name = &#39;layer{:03d}&#39;.format(i)
                                db[layer_name] = layer.get_weights()

        def print_summary(self):
                &#34;&#34;&#34;Print a summary of the sequential model in a table.&#34;&#34;&#34;

                spacer = &#39;+&#39; + &#39;-&#39; * 22 + &#39;+&#39; + &#39;-&#39; * 15 + &#39;+&#39; + &#39;-&#39; * 23 + &#39;+&#39; + &#39;-&#39; * 23 + &#39;+&#39; + &#39;-&#39; * 32 + &#39;+&#39;
                total_params = self.count_params()
                trainable_params = self.count_params(trainable_only=True)

                print()
                print(&#39;Sequential Model: {}&#39;.format(self.name))
                print(spacer)
                print(&#39;| {:20s} | {:13s} | {:&gt;21s} | {:&gt;21s} | {:30s} |&#39;.format(&#39;Layer Type:&#39;, &#39;num_of_params&#39;,
                                                                                                                &#39;input_shape&#39;, &#39;output_shape&#39;, &#39;layer_name&#39;))
                print(spacer)
                for layer in self.layers:
                        print(&#39;| &#39;, layer.summary(), &#39; |&#39;, sep=&#39;&#39;)
                print(spacer)
                print(&#39;| {:117s} |&#39;.format(&#39;Total Params: {}&#39;.format(total_params)))
                print(&#39;| {:117s} |&#39;.format(&#39;Trainable Params: {}&#39;.format(trainable_params)))
                print(&#39;| {:117s} |&#39;.format(&#39;Non-Trainable Params: {}&#39;.format(total_params - trainable_params)))
                print(spacer)
                print()

        # Model as a Layer Functionality:

        def __call__(self, x, training=False):
                a = x
                for layer in self.layers:
                        a = layer(a, training)
                return a

        def diff(self, da):
                Dw = []
                Db = []

                for layer in reversed(self.layers):
                        da, dw, db = layer.diff(da)
                        Dw.insert(0, dw)
                        Db.insert(0, db)

                return da, Dw, Db

        def add_input_shape_to_layers(self, n_in):
                if n_in != self.n_in:
                        raise UnsupportedShapeError(n_in, self.n_in)
                if self.layers:
                        return self.layers[-1].n_out

        def count_params(self, trainable_only=False):
                if trainable_only:
                        return np.sum([layer.count_params() for layer in self.layers if layer.trainable])
                else:
                        return np.sum([layer.count_params() for layer in self.layers])

        def get_weights(self):
                weights = []
                biases  = []
                for layer in self.layers:
                        w, b = layer.get_weights()
                        weights.append(w)
                        biases.append(b)
                return weights, biases

        def set_weights(self, weights, biases):
                for i, layer in enumerate(self.layers):
                        if layer.trainable:
                                layer.set_weights(weights[i], biases[i])</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ainshamsflow.models.load_model"><code class="name flex">
<span>def <span class="ident">load_model</span></span>(<span>filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads a model saved in 'filename'.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_model(filename):
        &#34;&#34;&#34;Loads a model saved in &#39;filename&#39;.&#34;&#34;&#34;

        with shelve.open(filename) as db:
                model = db[&#39;self&#39;]
        return model</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ainshamsflow.models.Model"><code class="flex name class">
<span>class <span class="ident">Model</span></span>
<span>(</span><span>input_shape, name, trainable=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Models Base Class.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_shape</code></strong></dt>
<dd>tuple showing the shape of the input to the model.</dd>
<dt><strong><code>name</code></strong></dt>
<dd>Name of the model.</dd>
<dt><strong><code>trainable</code></strong></dt>
<dd>Boolean to define whether this model is trainable or not.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Model(_layers.Layer):
        &#34;&#34;&#34;Models Base Class.&#34;&#34;&#34;

        def __init__(self, input_shape, name, trainable=True):
                &#34;&#34;&#34;
                Args:
                        input_shape: tuple showing the shape of the input to the model.
                        name: Name of the model.
                        trainable: Boolean to define whether this model is trainable or not.
                &#34;&#34;&#34;

                if not isinstance(input_shape, tuple):
                        raise WrongObjectError(input_shape, tuple())
                if len(input_shape) &lt;= 0:
                        raise InvalidShapeError(input_shape)
                for ch in input_shape:
                        if ch &lt;= 0:
                                raise InvalidShapeError(input_shape)

                super().__init__(name, trainable)
                self.n_in = input_shape
                self.n_out = None
                self.input_shape = &#39;(None&#39; + (&#39;,{:4}&#39;*len(self.n_in)).format(*self.n_in) + &#39;)&#39;
                self.output_shape = None

                self.optimizer = None
                self.loss = None
                self.metrics = None
                self.regularizer = None

        def compile(self, optimizer, loss, metrics=None, regularizer=None):
                &#34;&#34;&#34;Define model optimizer, loss function , metrics and regularizer.

                All arguments can be either an instance of the required class,
                or a string for a class that exists in the framework.

                Args:
                        optimizer: the optimizer used for training.
                        loss: loss function used for training.
                        metrics: a list of metrics (and/or losses) used to monitor training progress.
                        regularizer: regularizer used during training.
                &#34;&#34;&#34;
                if isinstance(optimizer, str):
                        optimizer = optimizers.get(optimizer)
                if not isinstance(optimizer, optimizers.Optimizer):
                        raise WrongObjectError(optimizer, optimizers.Optimizer())

                if isinstance(loss, str):
                        loss = losses.get(loss)
                if not isinstance(loss, losses.Loss):
                        raise WrongObjectError(loss, losses.Loss())

                if metrics:
                        if not isinstance(metrics, list):
                                raise WrongObjectError(metrics, list())
                        for i in range(len(metrics)):
                                if isinstance(metrics[i], str):
                                        metrics[i] = _metrics.get(metrics[i])
                                if not isinstance(metrics[i], _metrics.Metric):
                                        raise WrongObjectError(metrics[i], _metrics.Metric())
                else:
                        metrics = []

                if regularizer is not None:
                        if isinstance(regularizer, str):
                                regularizer = regularizers.get(regularizer)
                        if not isinstance(regularizer, regularizers.Regularizer):
                                raise WrongObjectError(regularizer, regularizers.Regularizer())


                self.optimizer = optimizer
                self.loss = loss
                self.metrics = metrics
                self.regularizer = regularizer

        def evaluate(self, x, y, batch_size):
                raise BaseClassError

        def fit(self, x, y, epochs, batch_size):
                raise BaseClassError

        def predict(self, x):
                &#34;&#34;&#34;Predict new data.

                Args:
                        x: input data to be passed through the model.
                &#34;&#34;&#34;

                if isinstance(x, Dataset):
                        x = x.data

                return self.__call__(x)

        def add_layer(self, layer):
                raise BaseClassError

        def get_layer(self, layer_name, index):
                raise BaseClassError

        def pop_layer(self):
                raise BaseClassError

        def load_weights(self, filepath):
                raise BaseClassError

        def save_weights(self, filepath):
                raise BaseClassError

        def save_model(self, filename):
                &#34;&#34;&#34;Saves model by its name in the directory specified.&#34;&#34;&#34;

                with shelve.open(filename) as db:
                        db[&#39;self&#39;] = self

        def print_summary(self):
                raise BaseClassError</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="ainshamsflow.layers.Layer" href="layers.html#ainshamsflow.layers.Layer">Layer</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="ainshamsflow.models.Sequential" href="#ainshamsflow.models.Sequential">Sequential</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="ainshamsflow.models.Model.compile"><code class="name flex">
<span>def <span class="ident">compile</span></span>(<span>self, optimizer, loss, metrics=None, regularizer=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Define model optimizer, loss function , metrics and regularizer.</p>
<p>All arguments can be either an instance of the required class,
or a string for a class that exists in the framework.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>optimizer</code></strong></dt>
<dd>the optimizer used for training.</dd>
<dt><strong><code>loss</code></strong></dt>
<dd>loss function used for training.</dd>
<dt><strong><code>metrics</code></strong></dt>
<dd>a list of metrics (and/or losses) used to monitor training progress.</dd>
<dt><strong><code>regularizer</code></strong></dt>
<dd>regularizer used during training.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compile(self, optimizer, loss, metrics=None, regularizer=None):
        &#34;&#34;&#34;Define model optimizer, loss function , metrics and regularizer.

        All arguments can be either an instance of the required class,
        or a string for a class that exists in the framework.

        Args:
                optimizer: the optimizer used for training.
                loss: loss function used for training.
                metrics: a list of metrics (and/or losses) used to monitor training progress.
                regularizer: regularizer used during training.
        &#34;&#34;&#34;
        if isinstance(optimizer, str):
                optimizer = optimizers.get(optimizer)
        if not isinstance(optimizer, optimizers.Optimizer):
                raise WrongObjectError(optimizer, optimizers.Optimizer())

        if isinstance(loss, str):
                loss = losses.get(loss)
        if not isinstance(loss, losses.Loss):
                raise WrongObjectError(loss, losses.Loss())

        if metrics:
                if not isinstance(metrics, list):
                        raise WrongObjectError(metrics, list())
                for i in range(len(metrics)):
                        if isinstance(metrics[i], str):
                                metrics[i] = _metrics.get(metrics[i])
                        if not isinstance(metrics[i], _metrics.Metric):
                                raise WrongObjectError(metrics[i], _metrics.Metric())
        else:
                metrics = []

        if regularizer is not None:
                if isinstance(regularizer, str):
                        regularizer = regularizers.get(regularizer)
                if not isinstance(regularizer, regularizers.Regularizer):
                        raise WrongObjectError(regularizer, regularizers.Regularizer())


        self.optimizer = optimizer
        self.loss = loss
        self.metrics = metrics
        self.regularizer = regularizer</code></pre>
</details>
</dd>
<dt id="ainshamsflow.models.Model.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Predict new data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong></dt>
<dd>input data to be passed through the model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, x):
        &#34;&#34;&#34;Predict new data.

        Args:
                x: input data to be passed through the model.
        &#34;&#34;&#34;

        if isinstance(x, Dataset):
                x = x.data

        return self.__call__(x)</code></pre>
</details>
</dd>
<dt id="ainshamsflow.models.Model.save_model"><code class="name flex">
<span>def <span class="ident">save_model</span></span>(<span>self, filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Saves model by its name in the directory specified.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_model(self, filename):
        &#34;&#34;&#34;Saves model by its name in the directory specified.&#34;&#34;&#34;

        with shelve.open(filename) as db:
                db[&#39;self&#39;] = self</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="ainshamsflow.layers.Layer" href="layers.html#ainshamsflow.layers.Layer">Layer</a></b></code>:
<ul class="hlist">
<li><code><a title="ainshamsflow.layers.Layer.add_input_shape_to_layer" href="layers.html#ainshamsflow.layers.Layer.add_input_shape_to_layer">add_input_shape_to_layer</a></code></li>
<li><code><a title="ainshamsflow.layers.Layer.count_params" href="layers.html#ainshamsflow.layers.Layer.count_params">count_params</a></code></li>
<li><code><a title="ainshamsflow.layers.Layer.diff" href="layers.html#ainshamsflow.layers.Layer.diff">diff</a></code></li>
<li><code><a title="ainshamsflow.layers.Layer.get_weights" href="layers.html#ainshamsflow.layers.Layer.get_weights">get_weights</a></code></li>
<li><code><a title="ainshamsflow.layers.Layer.set_weights" href="layers.html#ainshamsflow.layers.Layer.set_weights">set_weights</a></code></li>
<li><code><a title="ainshamsflow.layers.Layer.summary" href="layers.html#ainshamsflow.layers.Layer.summary">summary</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="ainshamsflow.models.Sequential"><code class="flex name class">
<span>class <span class="ident">Sequential</span></span>
<span>(</span><span>layers, input_shape, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Sequential Model Class.
Used to create Models where there is a strict, linear, layer-by-layer
structure.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>layers</code></strong></dt>
<dd>list of layers in order of data path.
must be a list of layer objects.</dd>
<dt><strong><code>input_shape</code></strong></dt>
<dd>tuple showing the shape of the input to the model.</dd>
<dt><strong><code>name</code></strong></dt>
<dd>name of the model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Sequential(Model):
        &#34;&#34;&#34;Sequential Model Class.
        Used to create Models where there is a strict, linear, layer-by-layer
        structure.
        &#34;&#34;&#34;

        __name__ = &#39;Seq. Model&#39;

        def __init__(self, layers, input_shape, name=None):
                &#34;&#34;&#34;
                Args:
                        layers: list of layers in order of data path.
                                must be a list of layer objects.
                        input_shape: tuple showing the shape of the input to the model.
                        name: name of the model.
                &#34;&#34;&#34;

                if not isinstance(layers, list):
                        raise WrongObjectError(layers, list())
                for layer in layers:
                        if not isinstance(layer, _layers.Layer):
                                raise WrongObjectError(layer, _layers.Layer())
                if not isinstance(input_shape, tuple):
                        raise WrongObjectError(input_shape, tuple())

                super().__init__(input_shape, name)
                self.layers = layers

                for layer in self.layers:
                        input_shape = layer.add_input_shape_to_layers(input_shape)

                self.n_out = self.layers[-1].n_out
                n_out = [str(ch) for ch in self.n_out]
                self.output_shape = &#39;(None&#39; + (&#39;,{:4}&#39;*len(n_out)).format(*n_out) + &#39;)&#39;

        def fit(self, x, y=None, epochs=1, batch_size=None, verbose=True, shuffle=True,
                        valid_split=None, valid_data=None, valid_batch_size=None):
                &#34;&#34;&#34;Fit the model to the training data.

                Args:
                        x: Either an Array of data features. must be of the same shape as the model&#39;s
                                `input_shape`.
                                __OR__ a dataset object that may include the data and labels for training.

                        y: This is the array of data labels.
                                Only used if `x` doesn&#39;t have the labels included in the dataset object.

                        epochs: number of rounds gone through the training set during training.

                        batch_size: size of the mini-batch used during training:
                                `None` =&gt; batch training,
                                `1` =&gt; online training,
                                other int =&gt; mini-batch training.

                        verbose: Whether to print training data or not during training.

                        shuffle: Whether to shuffle the training data before training.

                        valid_split: how much to split the training set to get a new validation set.
                                (0 &lt; `valid_split` &lt; 1)
                                Valid only if `valid_data` is `None`

                        valid_data: The validation set used in showing the training statistics.
                                Either a tuple: (`x_valid`, `y_valid`) __OR__ a dataset object with data
                                features and labels included.

                        valid_batch_size: size of the mini-batch used during evaluation of the
                                validation set:
                                `None` =&gt; batch training,
                                `1` =&gt; online training,
                                other int =&gt; mini-batch training.

                Returns:
                        history: history object used to plot the training statistics.
                                you can plot the learning curves by using:

                ```python
                &gt;&gt;&gt; history = model.fit(...)
                &gt;&gt;&gt; history.show()
                ```
                &#34;&#34;&#34;

                if self.optimizer is None:
                        raise UncompiledModelError

                ds_train = get_dataset_from_xy(x, y)

                if valid_data is not None:
                        if isinstance(valid_data, tuple):
                                ds_valid = get_dataset_from_xy(*valid_data)
                        else:
                                ds_valid = get_dataset_from_xy(valid_data, None)
                elif valid_split is not None:
                        ds_train, ds_valid = ds_train.split(valid_split)
                else:
                        ds_valid = None

                if shuffle:
                        ds_train.shuffle()

                return self.optimizer(ds_train, ds_valid, epochs, batch_size, valid_batch_size, self.layers,
                                                          self.loss, self.metrics, self.regularizer, verbose=verbose, training=True)

        def evaluate(self, x, y=None, batch_size=None, verbose=True):
                &#34;&#34;&#34;Evaluate the model on validation data.

                Args:
                        x: Either an Array of data features. must be of the same shape as the model&#39;s
                                `input_shape`.
                                __OR__ a dataset object that may include the data and labels for training.

                        y: This is the array of data labels.
                                Only used if `x` doesn&#39;t have the labels included in the dataset object.

                        batch_size: size of the mini-batch used during evaluation:
                                `None` =&gt; batch evaluation,
                                `1` =&gt; online evaluation,
                                other int =&gt; mini-batch evaluation.

                        verbose: Whether to print the evaluation data or return it.

                Returns:
                        None: if `verbose` = `True` __OR__
                        loss_value: value of the loss function.
                        metric_values: list of the metric values for all metrics.

                &#34;&#34;&#34;

                ds = get_dataset_from_xy(x, y)

                if self.optimizer is None:
                        raise UncompiledModelError
                return self.optimizer(ds, None,  1, batch_size, None, self.layers, self.loss, self.metrics, self.regularizer,
                                                                 verbose=verbose, training=False)

        def add_layer(self, layer):
                &#34;&#34;&#34;Add a new layer to the network.&#34;&#34;&#34;

                if not isinstance(layer, _layers.Layer):
                        raise WrongObjectError(layer, _layers.Layer())

                if self.layers:
                        n_out = self.layers[-1].n_out
                else:
                        n_out = self.n_in
                self.layers.append(layer)
                layer.add_input_shape_to_layer(n_out)

        def get_layer(self, *, index=None, layer_name=None):
                &#34;&#34;&#34;Get a specific layer from the model.

                You can either access the layer using it&#39;s name __xor__ it&#39;s index.
                &#34;&#34;&#34;

                if (index is None) ^ (layer_name is None):
                        if not isinstance(index, int):
                                raise WrongObjectError(index, 1)
                        if not isinstance(layer_name, str):
                                raise WrongObjectError(layer_name, &#39;&#39;)

                        if index is None:
                                for layer in self.layers:
                                        if layer.name == layer_name:
                                                return layer
                                raise LayerNotFoundError(&#39;name&#39;, layer_name)
                        elif index &lt; len(self.layers):
                                return self.layers[index]
                        else:
                                raise LayerNotFoundError(&#39;id&#39;, index)
                else:
                        raise MultipleAccessError

        def pop_layer(self):
                &#34;&#34;&#34;Pop the last layer from the model.&#34;&#34;&#34;

                if self.layers:
                        self.layers.pop()

        def load_weights(self, filepath):
                &#34;&#34;&#34;Load weights from a directory.&#34;&#34;&#34;

                with shelve.open(join_path(filepath, self.name+&#39;_weights&#39;)) as db:
                        for i in range(len(self.layers)):
                                layer_name = &#39;layer{:03d}&#39;.format(i)
                                self.layers[i] = db[layer_name]

        def save_weights(self, filepath):
                &#34;&#34;&#34;Save weights to a directory.&#34;&#34;&#34;

                with shelve.open(join_path(filepath, self.name+&#39;_weights&#39;)) as db:
                        for i, layer in enumerate(self.layers):
                                layer_name = &#39;layer{:03d}&#39;.format(i)
                                db[layer_name] = layer.get_weights()

        def print_summary(self):
                &#34;&#34;&#34;Print a summary of the sequential model in a table.&#34;&#34;&#34;

                spacer = &#39;+&#39; + &#39;-&#39; * 22 + &#39;+&#39; + &#39;-&#39; * 15 + &#39;+&#39; + &#39;-&#39; * 23 + &#39;+&#39; + &#39;-&#39; * 23 + &#39;+&#39; + &#39;-&#39; * 32 + &#39;+&#39;
                total_params = self.count_params()
                trainable_params = self.count_params(trainable_only=True)

                print()
                print(&#39;Sequential Model: {}&#39;.format(self.name))
                print(spacer)
                print(&#39;| {:20s} | {:13s} | {:&gt;21s} | {:&gt;21s} | {:30s} |&#39;.format(&#39;Layer Type:&#39;, &#39;num_of_params&#39;,
                                                                                                                &#39;input_shape&#39;, &#39;output_shape&#39;, &#39;layer_name&#39;))
                print(spacer)
                for layer in self.layers:
                        print(&#39;| &#39;, layer.summary(), &#39; |&#39;, sep=&#39;&#39;)
                print(spacer)
                print(&#39;| {:117s} |&#39;.format(&#39;Total Params: {}&#39;.format(total_params)))
                print(&#39;| {:117s} |&#39;.format(&#39;Trainable Params: {}&#39;.format(trainable_params)))
                print(&#39;| {:117s} |&#39;.format(&#39;Non-Trainable Params: {}&#39;.format(total_params - trainable_params)))
                print(spacer)
                print()

        # Model as a Layer Functionality:

        def __call__(self, x, training=False):
                a = x
                for layer in self.layers:
                        a = layer(a, training)
                return a

        def diff(self, da):
                Dw = []
                Db = []

                for layer in reversed(self.layers):
                        da, dw, db = layer.diff(da)
                        Dw.insert(0, dw)
                        Db.insert(0, db)

                return da, Dw, Db

        def add_input_shape_to_layers(self, n_in):
                if n_in != self.n_in:
                        raise UnsupportedShapeError(n_in, self.n_in)
                if self.layers:
                        return self.layers[-1].n_out

        def count_params(self, trainable_only=False):
                if trainable_only:
                        return np.sum([layer.count_params() for layer in self.layers if layer.trainable])
                else:
                        return np.sum([layer.count_params() for layer in self.layers])

        def get_weights(self):
                weights = []
                biases  = []
                for layer in self.layers:
                        w, b = layer.get_weights()
                        weights.append(w)
                        biases.append(b)
                return weights, biases

        def set_weights(self, weights, biases):
                for i, layer in enumerate(self.layers):
                        if layer.trainable:
                                layer.set_weights(weights[i], biases[i])</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="ainshamsflow.models.Model" href="#ainshamsflow.models.Model">Model</a></li>
<li><a title="ainshamsflow.layers.Layer" href="layers.html#ainshamsflow.layers.Layer">Layer</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="ainshamsflow.models.Sequential.add_layer"><code class="name flex">
<span>def <span class="ident">add_layer</span></span>(<span>self, layer)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a new layer to the network.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_layer(self, layer):
        &#34;&#34;&#34;Add a new layer to the network.&#34;&#34;&#34;

        if not isinstance(layer, _layers.Layer):
                raise WrongObjectError(layer, _layers.Layer())

        if self.layers:
                n_out = self.layers[-1].n_out
        else:
                n_out = self.n_in
        self.layers.append(layer)
        layer.add_input_shape_to_layer(n_out)</code></pre>
</details>
</dd>
<dt id="ainshamsflow.models.Sequential.count_params"><code class="name flex">
<span>def <span class="ident">count_params</span></span>(<span>self, trainable_only=False)</span>
</code></dt>
<dd>
<div class="desc"><p>No Parameters in this layer. Returns 0.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count_params(self, trainable_only=False):
        if trainable_only:
                return np.sum([layer.count_params() for layer in self.layers if layer.trainable])
        else:
                return np.sum([layer.count_params() for layer in self.layers])</code></pre>
</details>
</dd>
<dt id="ainshamsflow.models.Sequential.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, x, y=None, batch_size=None, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate the model on validation data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong></dt>
<dd>Either an Array of data features. must be of the same shape as the model's
<code>input_shape</code>.
<strong>OR</strong> a dataset object that may include the data and labels for training.</dd>
<dt><strong><code>y</code></strong></dt>
<dd>This is the array of data labels.
Only used if <code>x</code> doesn't have the labels included in the dataset object.</dd>
<dt><strong><code>batch_size</code></strong></dt>
<dd>size of the mini-batch used during evaluation:
<code>None</code> =&gt; batch evaluation,
<code>1</code> =&gt; online evaluation,
other int =&gt; mini-batch evaluation.</dd>
<dt><strong><code>verbose</code></strong></dt>
<dd>Whether to print the evaluation data or return it.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>if <code>verbose</code> = <code>True</code> <strong>OR</strong></dd>
<dt><code>loss_value</code></dt>
<dd>value of the loss function.</dd>
<dt><code>metric_values</code></dt>
<dd>list of the metric values for all metrics.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, x, y=None, batch_size=None, verbose=True):
        &#34;&#34;&#34;Evaluate the model on validation data.

        Args:
                x: Either an Array of data features. must be of the same shape as the model&#39;s
                        `input_shape`.
                        __OR__ a dataset object that may include the data and labels for training.

                y: This is the array of data labels.
                        Only used if `x` doesn&#39;t have the labels included in the dataset object.

                batch_size: size of the mini-batch used during evaluation:
                        `None` =&gt; batch evaluation,
                        `1` =&gt; online evaluation,
                        other int =&gt; mini-batch evaluation.

                verbose: Whether to print the evaluation data or return it.

        Returns:
                None: if `verbose` = `True` __OR__
                loss_value: value of the loss function.
                metric_values: list of the metric values for all metrics.

        &#34;&#34;&#34;

        ds = get_dataset_from_xy(x, y)

        if self.optimizer is None:
                raise UncompiledModelError
        return self.optimizer(ds, None,  1, batch_size, None, self.layers, self.loss, self.metrics, self.regularizer,
                                                         verbose=verbose, training=False)</code></pre>
</details>
</dd>
<dt id="ainshamsflow.models.Sequential.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, x, y=None, epochs=1, batch_size=None, verbose=True, shuffle=True, valid_split=None, valid_data=None, valid_batch_size=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Fit the model to the training data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong></dt>
<dd>Either an Array of data features. must be of the same shape as the model's
<code>input_shape</code>.
<strong>OR</strong> a dataset object that may include the data and labels for training.</dd>
<dt><strong><code>y</code></strong></dt>
<dd>This is the array of data labels.
Only used if <code>x</code> doesn't have the labels included in the dataset object.</dd>
<dt><strong><code>epochs</code></strong></dt>
<dd>number of rounds gone through the training set during training.</dd>
<dt><strong><code>batch_size</code></strong></dt>
<dd>size of the mini-batch used during training:
<code>None</code> =&gt; batch training,
<code>1</code> =&gt; online training,
other int =&gt; mini-batch training.</dd>
<dt><strong><code>verbose</code></strong></dt>
<dd>Whether to print training data or not during training.</dd>
<dt><strong><code>shuffle</code></strong></dt>
<dd>Whether to shuffle the training data before training.</dd>
<dt><strong><code>valid_split</code></strong></dt>
<dd>how much to split the training set to get a new validation set.
(0 &lt; <code>valid_split</code> &lt; 1)
Valid only if <code>valid_data</code> is <code>None</code></dd>
<dt><strong><code>valid_data</code></strong></dt>
<dd>The validation set used in showing the training statistics.
Either a tuple: (<code>x_valid</code>, <code>y_valid</code>) <strong>OR</strong> a dataset object with data
features and labels included.</dd>
<dt><strong><code>valid_batch_size</code></strong></dt>
<dd>size of the mini-batch used during evaluation of the
validation set:
<code>None</code> =&gt; batch training,
<code>1</code> =&gt; online training,
other int =&gt; mini-batch training.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>history</code></dt>
<dd>history object used to plot the training statistics.
you can plot the learning curves by using:</dd>
</dl>
<pre><code class="python">&gt;&gt;&gt; history = model.fit(...)
&gt;&gt;&gt; history.show()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, x, y=None, epochs=1, batch_size=None, verbose=True, shuffle=True,
                valid_split=None, valid_data=None, valid_batch_size=None):
        &#34;&#34;&#34;Fit the model to the training data.

        Args:
                x: Either an Array of data features. must be of the same shape as the model&#39;s
                        `input_shape`.
                        __OR__ a dataset object that may include the data and labels for training.

                y: This is the array of data labels.
                        Only used if `x` doesn&#39;t have the labels included in the dataset object.

                epochs: number of rounds gone through the training set during training.

                batch_size: size of the mini-batch used during training:
                        `None` =&gt; batch training,
                        `1` =&gt; online training,
                        other int =&gt; mini-batch training.

                verbose: Whether to print training data or not during training.

                shuffle: Whether to shuffle the training data before training.

                valid_split: how much to split the training set to get a new validation set.
                        (0 &lt; `valid_split` &lt; 1)
                        Valid only if `valid_data` is `None`

                valid_data: The validation set used in showing the training statistics.
                        Either a tuple: (`x_valid`, `y_valid`) __OR__ a dataset object with data
                        features and labels included.

                valid_batch_size: size of the mini-batch used during evaluation of the
                        validation set:
                        `None` =&gt; batch training,
                        `1` =&gt; online training,
                        other int =&gt; mini-batch training.

        Returns:
                history: history object used to plot the training statistics.
                        you can plot the learning curves by using:

        ```python
        &gt;&gt;&gt; history = model.fit(...)
        &gt;&gt;&gt; history.show()
        ```
        &#34;&#34;&#34;

        if self.optimizer is None:
                raise UncompiledModelError

        ds_train = get_dataset_from_xy(x, y)

        if valid_data is not None:
                if isinstance(valid_data, tuple):
                        ds_valid = get_dataset_from_xy(*valid_data)
                else:
                        ds_valid = get_dataset_from_xy(valid_data, None)
        elif valid_split is not None:
                ds_train, ds_valid = ds_train.split(valid_split)
        else:
                ds_valid = None

        if shuffle:
                ds_train.shuffle()

        return self.optimizer(ds_train, ds_valid, epochs, batch_size, valid_batch_size, self.layers,
                                                  self.loss, self.metrics, self.regularizer, verbose=verbose, training=True)</code></pre>
</details>
</dd>
<dt id="ainshamsflow.models.Sequential.get_layer"><code class="name flex">
<span>def <span class="ident">get_layer</span></span>(<span>self, *, index=None, layer_name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Get a specific layer from the model.</p>
<p>You can either access the layer using it's name <strong>xor</strong> it's index.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_layer(self, *, index=None, layer_name=None):
        &#34;&#34;&#34;Get a specific layer from the model.

        You can either access the layer using it&#39;s name __xor__ it&#39;s index.
        &#34;&#34;&#34;

        if (index is None) ^ (layer_name is None):
                if not isinstance(index, int):
                        raise WrongObjectError(index, 1)
                if not isinstance(layer_name, str):
                        raise WrongObjectError(layer_name, &#39;&#39;)

                if index is None:
                        for layer in self.layers:
                                if layer.name == layer_name:
                                        return layer
                        raise LayerNotFoundError(&#39;name&#39;, layer_name)
                elif index &lt; len(self.layers):
                        return self.layers[index]
                else:
                        raise LayerNotFoundError(&#39;id&#39;, index)
        else:
                raise MultipleAccessError</code></pre>
</details>
</dd>
<dt id="ainshamsflow.models.Sequential.load_weights"><code class="name flex">
<span>def <span class="ident">load_weights</span></span>(<span>self, filepath)</span>
</code></dt>
<dd>
<div class="desc"><p>Load weights from a directory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_weights(self, filepath):
        &#34;&#34;&#34;Load weights from a directory.&#34;&#34;&#34;

        with shelve.open(join_path(filepath, self.name+&#39;_weights&#39;)) as db:
                for i in range(len(self.layers)):
                        layer_name = &#39;layer{:03d}&#39;.format(i)
                        self.layers[i] = db[layer_name]</code></pre>
</details>
</dd>
<dt id="ainshamsflow.models.Sequential.pop_layer"><code class="name flex">
<span>def <span class="ident">pop_layer</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Pop the last layer from the model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pop_layer(self):
        &#34;&#34;&#34;Pop the last layer from the model.&#34;&#34;&#34;

        if self.layers:
                self.layers.pop()</code></pre>
</details>
</dd>
<dt id="ainshamsflow.models.Sequential.print_summary"><code class="name flex">
<span>def <span class="ident">print_summary</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Print a summary of the sequential model in a table.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_summary(self):
        &#34;&#34;&#34;Print a summary of the sequential model in a table.&#34;&#34;&#34;

        spacer = &#39;+&#39; + &#39;-&#39; * 22 + &#39;+&#39; + &#39;-&#39; * 15 + &#39;+&#39; + &#39;-&#39; * 23 + &#39;+&#39; + &#39;-&#39; * 23 + &#39;+&#39; + &#39;-&#39; * 32 + &#39;+&#39;
        total_params = self.count_params()
        trainable_params = self.count_params(trainable_only=True)

        print()
        print(&#39;Sequential Model: {}&#39;.format(self.name))
        print(spacer)
        print(&#39;| {:20s} | {:13s} | {:&gt;21s} | {:&gt;21s} | {:30s} |&#39;.format(&#39;Layer Type:&#39;, &#39;num_of_params&#39;,
                                                                                                        &#39;input_shape&#39;, &#39;output_shape&#39;, &#39;layer_name&#39;))
        print(spacer)
        for layer in self.layers:
                print(&#39;| &#39;, layer.summary(), &#39; |&#39;, sep=&#39;&#39;)
        print(spacer)
        print(&#39;| {:117s} |&#39;.format(&#39;Total Params: {}&#39;.format(total_params)))
        print(&#39;| {:117s} |&#39;.format(&#39;Trainable Params: {}&#39;.format(trainable_params)))
        print(&#39;| {:117s} |&#39;.format(&#39;Non-Trainable Params: {}&#39;.format(total_params - trainable_params)))
        print(spacer)
        print()</code></pre>
</details>
</dd>
<dt id="ainshamsflow.models.Sequential.save_weights"><code class="name flex">
<span>def <span class="ident">save_weights</span></span>(<span>self, filepath)</span>
</code></dt>
<dd>
<div class="desc"><p>Save weights to a directory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_weights(self, filepath):
        &#34;&#34;&#34;Save weights to a directory.&#34;&#34;&#34;

        with shelve.open(join_path(filepath, self.name+&#39;_weights&#39;)) as db:
                for i, layer in enumerate(self.layers):
                        layer_name = &#39;layer{:03d}&#39;.format(i)
                        db[layer_name] = layer.get_weights()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="ainshamsflow.models.Model" href="#ainshamsflow.models.Model">Model</a></b></code>:
<ul class="hlist">
<li><code><a title="ainshamsflow.models.Model.add_input_shape_to_layer" href="layers.html#ainshamsflow.layers.Layer.add_input_shape_to_layer">add_input_shape_to_layer</a></code></li>
<li><code><a title="ainshamsflow.models.Model.compile" href="#ainshamsflow.models.Model.compile">compile</a></code></li>
<li><code><a title="ainshamsflow.models.Model.predict" href="#ainshamsflow.models.Model.predict">predict</a></code></li>
<li><code><a title="ainshamsflow.models.Model.save_model" href="#ainshamsflow.models.Model.save_model">save_model</a></code></li>
<li><code><a title="ainshamsflow.models.Model.summary" href="layers.html#ainshamsflow.layers.Layer.summary">summary</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ainshamsflow" href="index.html">ainshamsflow</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ainshamsflow.models.load_model" href="#ainshamsflow.models.load_model">load_model</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ainshamsflow.models.Model" href="#ainshamsflow.models.Model">Model</a></code></h4>
<ul class="">
<li><code><a title="ainshamsflow.models.Model.compile" href="#ainshamsflow.models.Model.compile">compile</a></code></li>
<li><code><a title="ainshamsflow.models.Model.predict" href="#ainshamsflow.models.Model.predict">predict</a></code></li>
<li><code><a title="ainshamsflow.models.Model.save_model" href="#ainshamsflow.models.Model.save_model">save_model</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="ainshamsflow.models.Sequential" href="#ainshamsflow.models.Sequential">Sequential</a></code></h4>
<ul class="two-column">
<li><code><a title="ainshamsflow.models.Sequential.add_layer" href="#ainshamsflow.models.Sequential.add_layer">add_layer</a></code></li>
<li><code><a title="ainshamsflow.models.Sequential.count_params" href="#ainshamsflow.models.Sequential.count_params">count_params</a></code></li>
<li><code><a title="ainshamsflow.models.Sequential.evaluate" href="#ainshamsflow.models.Sequential.evaluate">evaluate</a></code></li>
<li><code><a title="ainshamsflow.models.Sequential.fit" href="#ainshamsflow.models.Sequential.fit">fit</a></code></li>
<li><code><a title="ainshamsflow.models.Sequential.get_layer" href="#ainshamsflow.models.Sequential.get_layer">get_layer</a></code></li>
<li><code><a title="ainshamsflow.models.Sequential.load_weights" href="#ainshamsflow.models.Sequential.load_weights">load_weights</a></code></li>
<li><code><a title="ainshamsflow.models.Sequential.pop_layer" href="#ainshamsflow.models.Sequential.pop_layer">pop_layer</a></code></li>
<li><code><a title="ainshamsflow.models.Sequential.print_summary" href="#ainshamsflow.models.Sequential.print_summary">print_summary</a></code></li>
<li><code><a title="ainshamsflow.models.Sequential.save_weights" href="#ainshamsflow.models.Sequential.save_weights">save_weights</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>