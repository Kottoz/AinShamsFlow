<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ainshamsflow.data API documentation</title>
<meta name="description" content="Data Module â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ainshamsflow.data</code></h1>
</header>
<section id="section-intro">
<p>Data Module.</p>
<p>In this Module, we include our dataset handling classes. These include a general purpose Dataset class
and a ImageDataGenerator Class that is more specific to dealing with Images inside directories.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Data Module.

In this Module, we include our dataset handling classes. These include a general purpose Dataset class
and a ImageDataGenerator Class that is more specific to dealing with Images inside directories.
&#34;&#34;&#34;

import numpy as np
import matplotlib.image as mpimg
import os

from ainshamsflow.utils.asf_errors import UnsupportedShapeError, UninitializedDatasetError

__pdoc__ = dict()

__pdoc__[&#39;Dataset.__bool__&#39;] = True
__pdoc__[&#39;Dataset.__len__&#39;] = True
__pdoc__[&#39;Dataset.__iter__&#39;] = True
__pdoc__[&#39;Dataset.__next__&#39;] = True


class Dataset:
        def __init__(self, x=None, y=None):
                self.data = None
                self.target = None
                if x is not None:
                        self.data = np.array(x)
                if y is not None:
                        self.target = np.array(y)
                if x is not None and y is not None:
                        if self.data.shape[0] != self.target.shape[0]:
                                raise UnsupportedShapeError(x.shape[0], y.shape[0])
                self.is_batched = False

        def __bool__(self):
                &#34;&#34;&#34;Returns True if the Dataset is not None.&#34;&#34;&#34;
                return self.data is not None

        def __len__(self):
                &#34;&#34;&#34;Returns the number of data points in the dataset.&#34;&#34;&#34;
                return self.cardinality()

        def __iter__(self):
                &#34;&#34;&#34;Defines the Dataset as an Interator.

                Enables the user to do this:
                ```python
                &gt;&gt;&gt; for x, y in ds.batch(1):
                ...     print(x, y)
                ```
                &#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError

                if not self.is_batched:
                        self.batch(self.cardinality())

                self.index = 0
                return self

        def __next__(self):
                &#34;&#34;&#34;Defines the Dataset as an Interator.

                Enables the user to do this:
                ```python
                &gt;&gt;&gt; for x, y in ds.batch(1):
                ...     print(x, y)
                ```
                &#34;&#34;&#34;
                if self.index &gt;= self.data.shape[0]:
                        raise StopIteration

                if self.data is not None and self.target is not None:
                        x = self.data[self.index]
                        y = self.target[self.index]
                        self.index += 1
                        return x, y

                elif self.data is not None:
                        x = self.data[self.index]
                        self.index += 1
                        return x

        def copy(self):
                &#34;&#34;&#34; Returns a copy of the dataset.&#34;&#34;&#34;
                dataset_copy = Dataset()
                dataset_copy.data = np.copy(self.data)
                dataset_copy.target = np.copy(self.target)
                return dataset_copy

        def apply(self, transformation):
                &#34;&#34;&#34;Applies a transformation function to this dataset.
                Args:
                           transformation: a function that applies to the dataset as a whole.
                Returns:
                         Dataset After transformation
                &#34;&#34;&#34;
                return transformation(self)

        def batch(self, batch_size):
                &#34;&#34;&#34; Divides the dataset into equal parts of size equals batch_size.

                If the dataset is already batched, this functions unbaches first, then baches the data
                again with the new batch_size.

                Args:
                        batch_size: the size of the batches
                &#34;&#34;&#34;
                if self.is_batched:
                        self.unbatch()

                if self.data is None:
                        raise UninitializedDatasetError

                m = self.data.shape[0]
                remainder = m % batch_size

                self.take(m-remainder)

                _, *nd = self.data.shape
                _, *nt = self.target.shape
                self.data = self.data.reshape((-1, batch_size, *nd))
                self.target = self.target.reshape((-1, batch_size, *nt))

                self.is_batched = True
                return self

        def unbatch(self):
                &#34;&#34;&#34;Unbatches the Dataset if batched&#34;&#34;&#34;
                if self.is_batched:
                        n1d, n2d, *nd = self.data.shape
                        self.data = self.data.reshape((n1d*n2d, *nd))
                        if self.target is not None:
                                n1t, n2t, *nt = self.target.shape
                                self.target = self.target.reshape((n1t*n2t, *nt))
                return self

        def cardinality(self):
                &#34;&#34;&#34; Returns the number of data points in the dataset.&#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError

                if self.is_batched:
                        return self.data.shape[0] * self.data.shape[1]
                else:
                        return self.data.shape[0]

        def concatenate(self, ds_list):
                &#34;&#34;&#34;Concatenates this Dataset with any number of datasets.

                Args:
                        ds_list: a list of datasets to use for concatenation.
                &#34;&#34;&#34;

                if self.data is None:
                        raise UninitializedDatasetError
                for ds in ds_list:
                        if ds.data is None:
                                raise UninitializedDatasetError

                self.data = np.concatenate((self.data, *[ds.data for ds in ds_list]))
                if self.target is not None:
                        self.target = np.concatenate((self.target, *[ds.target for ds in ds_list]))
                return self

        def enumerate(self):
                &#34;&#34;&#34;Enumerates the dataset into numbered data elements.

                enables the user to do this:
                ```python
                &gt;&gt;&gt; ds.enumerate().batch(1)
                &gt;&gt;&gt; for (i, x), y in ds:
                ...     print(i, x, y)
                ```
                &#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError
                enum = []
                for i in range(self.cardinality()):
                        enum.append([i, self.data[i]])
                self.data = np.array(enum)
                return self

        def filter(self, function):
                &#34;&#34;&#34;Filters the dataset given a certain function.

                Args:
                        function: specifies a condition [function(x)] to keep each element x in the dataset.
                &#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError
                new_data = []
                for x in self.data:
                        if function(x):
                                new_data.append(x)
                self.data = np.array(new_data)
                return self

        def numpy(self):
                &#34;&#34;&#34;Returns the Dataset in a numpy format.

                Returns:
                        dataset features: if dataset is not labeled
                        dataset features, dataset labels: if dataset is labeled
                &#34;&#34;&#34;
                if self.data is None and self.target is None:
                        raise UninitializedDatasetError
                elif self.target is None:
                        return self.data
                elif self.data is None:
                        return self.target
                else:
                        return self.data, self.target

        def map(self, function):
                &#34;&#34;&#34;Maps each element in the dataset with the function map.&#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError
                function = np.vectorize(function)
                return function(self.data)

        def range(self, *args):
                &#34;&#34;&#34;Returns a new Dataset with data as a numbered list.

                uses the same syntax as np.arange()
                &#34;&#34;&#34;
                self.data = np.arange(*args)
                return self

        def shuffle(self):
                &#34;&#34;&#34;Arrays shuffled in-place by their first dimension&#34;&#34;&#34;

                if self.data is None:
                        raise UninitializedDatasetError

                # Generate random seed
                seed = np.random.randint(0, 2 ** (32 - 1) - 1)

                if self.target is not None:
                        # Shuffle both arrays in-place using the same seed
                        for array in [self.data, self.target]:
                                # Generate random state object
                                r_state = np.random.RandomState(seed)
                                r_state.shuffle(array)

                else:
                        # Generate random state object and only shuffle the data array
                        r_state = np.random.RandomState(seed)
                        r_state.shuffle(self.data)

                return self

        def split(self, split_percentage, shuffle=False):
                &#34;&#34;&#34;Splits the dataset into 2 batches (training and testing/validation)

                        Args:
                                split_percentage: (float) percentage of the testing/validation data points
                                shuffle: (bool) if true, the data is shuffled before the split

                        Returns:
                                If the dataset was initialized with x only:     returns unlabeled ds_train, ds_test
                                If the dataset was initialized with x and y: returns labeled ds_train, ds_test
                &#34;&#34;&#34;

                if self.data is None:
                        raise UninitializedDatasetError
                holdout = int(split_percentage * self.data.shape[0])
                if shuffle:
                        self.shuffle()

                x_test = self.data[holdout:]
                x_train = self.data[:holdout]

                if self.target is not None:
                        y_test = self.target[holdout:]
                        y_train = self.target[:holdout]
                else:
                        y_train = None
                        y_test = None

                return Dataset(x=x_train, y=y_train), Dataset(x=x_test, y=y_test)

        def take(self, limit):
                &#34;&#34;&#34;Takes the first N of data points in dataset to a given end.

                usefull for visulaizing the dataset as follows:
                ```python
                &gt;&gt;&gt; for x, y in ds.copy().take(5):
                ...     print(x, y)
                ```
                &#34;&#34;&#34;
                if self.data is None and self.target is None:
                        raise UninitializedDatasetError
                if self.data is not None:
                        self.data = self.data[:limit]
                if self.target is not None:
                        self.target = self.target[:limit]
                return self

        def skip(self, limit):
                &#34;&#34;&#34;a function that skips data in dataset from a given start.&#34;&#34;&#34;
                if self.data is None and self.target is None:
                        raise UninitializedDatasetError
                if self.data is not None:
                        self.data = self.data[limit:]
                if self.target is not None:
                        self.target = self.target[limit:]
                return self

        def add_data(self, x):
                &#34;&#34;&#34;Add features to a dataset.&#34;&#34;&#34;
                x = np.array(x)
                if self.target is not None:
                        if x.shape[0] != self.target.shape[0]:
                                raise UnsupportedShapeError(x.shape[0], self.target.shape[0])
                self.data = x
                return self

        def add_targets(self, y):
                &#34;&#34;&#34;add labels to a dataset.&#34;&#34;&#34;
                y = np.array(y)
                if self.data is not None:
                        if self.data.shape[0] != y.shape[0]:
                                raise UnsupportedShapeError(y.shape[0], self.data.shape[0])
                self.target = y

                return self

        def normalize(self):
                &#34;&#34;&#34;normalize the dataset so as to be centred around the origin.&#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError
                self.data = (self.data-self.data.mean(axis=0))/np.sqrt(self.data.var(axis=0)+1e-6)
                return self


class ImageDataGenerator(Dataset):
        &#34;&#34;&#34;Image Data Generator Class.

        This class helps in training large amounts of images with minimal memory allocation.
        &#34;&#34;&#34;
        def __init__(self):
                self.class_name = []
                self.dir = None
                super().__init__()

        def flow_from_directory(self, directory):
                &#34;&#34;&#34;Reads Images from a Directory.

                Args:
                        directory: If directory holds images only, this function will use these images as a dataset without any labels.
                                Otherwise, if the directory holds folders of images, it will store the folder names as class names in
                                the class_names attribute. It will then label the images according to their folders.
                &#34;&#34;&#34;
                self.dir = directory
                self.class_name = [name for name in os.listdir(directory)
                                                   if os.path.isdir(os.path.join(directory, name))]
                if class_name:
                        images = []
                        labels = []
                        for i in range(len(self.class_name)):
                                for img_name in os.listdir(self.class_name[i]):
                                        if os.path.isfile(os.path.join(directory, self.class_name[i], img_name)):
                                                images.append(img_name)
                                                labels.append(i)
                        self.data = np.array(images)
                        self.target = np.array(labels)
                else:
                        images = [img_name for img_name in os.listdir(directory)
                                           if os.path.isfile(os.path.join(directory, img_name))]
                        self.data = np.array(images)

                self.shuffle()
                return self

        def __next__(self):
                &#34;&#34;&#34;Defines the ImageDataGenerator as an Interator.

                Enables the user to do this:
                ```python
                &gt;&gt;&gt; for x, y in ds.batch(1):
                ...     print(x, y)
                ```
                &#34;&#34;&#34;
                if self.index &gt;= self.data.shape[0]:
                        raise StopIteration
                self.index += 1
                img = self._extract_img(self.data[self.index-1], self.target[self.index-1])
                if self.target is not None:
                        label = self.target[self.index-1]
                        return img, label
                else:
                        return img

        def _extract_img(self, filename, label):
                if isinstance(filename, str):
                        ans = mpimg.imread(os.path.join(self.dir, self.class_name[label], filename))
                else:
                        ans = []
                        for file, lab in zip(filename, label):
                                ans.append(self._extract_img(file, lab))
                        ans = np.array(ans)
                return ans
        
        def copy(self):
                &#34;&#34;&#34;Returns a copy of the dataset.&#34;&#34;&#34;
                dataset_copy = ImageDataGenerator()
                dataset_copy.data = np.copy(self.data)
                dataset_copy.target = np.copy(self.target)
                dataset_copy.dir = self.dir
                dataset_copy.class_name = self.class_name[:]
                return dataset_copy
        
        def split(self, split_percentage, shuffle=False):
                &#34;&#34;&#34;Splits the dataset into 2 batches (training and testing/validation)

                        Args:
                                split_percentage: (float) percentage of the testing/validation data points
                                shuffle: (bool) if true, the data is shuffled before the split

                        Returns:
                                If the dataset was initialized with x only:     returns unlabeled ds_train, ds_test
                                If the dataset was initialized with x and y: returns labeled ds_train, ds_test
                &#34;&#34;&#34;

                if self.data is None:
                        raise UninitializedDatasetError
                img_gen_train = ImageDataGenerator()
                img_gen_test = ImageDataGenerator()
                
                img_gen_train.dir = img_gen_test.dir = self.dir
                img_gen_train.class_name = self.class_name[:]
                img_gen_test.class_name = self.class_name[:]
                
                holdout = int(split_percentage * self.data.shape[0])
                if shuffle:
                        self.shuffle()

                img_gen_train.data = self.data[:holdout]
                img_gen_test.data = self.data[holdout:]

                if self.target is not None:
                        img_gen_train.target = self.target[:holdout]
                        img_gen_test.target = self.target[holdout:]

                return img_gen_train, img_gen_test</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ainshamsflow.data.Dataset"><code class="flex name class">
<span>class <span class="ident">Dataset</span></span>
<span>(</span><span>x=None, y=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Dataset:
        def __init__(self, x=None, y=None):
                self.data = None
                self.target = None
                if x is not None:
                        self.data = np.array(x)
                if y is not None:
                        self.target = np.array(y)
                if x is not None and y is not None:
                        if self.data.shape[0] != self.target.shape[0]:
                                raise UnsupportedShapeError(x.shape[0], y.shape[0])
                self.is_batched = False

        def __bool__(self):
                &#34;&#34;&#34;Returns True if the Dataset is not None.&#34;&#34;&#34;
                return self.data is not None

        def __len__(self):
                &#34;&#34;&#34;Returns the number of data points in the dataset.&#34;&#34;&#34;
                return self.cardinality()

        def __iter__(self):
                &#34;&#34;&#34;Defines the Dataset as an Interator.

                Enables the user to do this:
                ```python
                &gt;&gt;&gt; for x, y in ds.batch(1):
                ...     print(x, y)
                ```
                &#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError

                if not self.is_batched:
                        self.batch(self.cardinality())

                self.index = 0
                return self

        def __next__(self):
                &#34;&#34;&#34;Defines the Dataset as an Interator.

                Enables the user to do this:
                ```python
                &gt;&gt;&gt; for x, y in ds.batch(1):
                ...     print(x, y)
                ```
                &#34;&#34;&#34;
                if self.index &gt;= self.data.shape[0]:
                        raise StopIteration

                if self.data is not None and self.target is not None:
                        x = self.data[self.index]
                        y = self.target[self.index]
                        self.index += 1
                        return x, y

                elif self.data is not None:
                        x = self.data[self.index]
                        self.index += 1
                        return x

        def copy(self):
                &#34;&#34;&#34; Returns a copy of the dataset.&#34;&#34;&#34;
                dataset_copy = Dataset()
                dataset_copy.data = np.copy(self.data)
                dataset_copy.target = np.copy(self.target)
                return dataset_copy

        def apply(self, transformation):
                &#34;&#34;&#34;Applies a transformation function to this dataset.
                Args:
                           transformation: a function that applies to the dataset as a whole.
                Returns:
                         Dataset After transformation
                &#34;&#34;&#34;
                return transformation(self)

        def batch(self, batch_size):
                &#34;&#34;&#34; Divides the dataset into equal parts of size equals batch_size.

                If the dataset is already batched, this functions unbaches first, then baches the data
                again with the new batch_size.

                Args:
                        batch_size: the size of the batches
                &#34;&#34;&#34;
                if self.is_batched:
                        self.unbatch()

                if self.data is None:
                        raise UninitializedDatasetError

                m = self.data.shape[0]
                remainder = m % batch_size

                self.take(m-remainder)

                _, *nd = self.data.shape
                _, *nt = self.target.shape
                self.data = self.data.reshape((-1, batch_size, *nd))
                self.target = self.target.reshape((-1, batch_size, *nt))

                self.is_batched = True
                return self

        def unbatch(self):
                &#34;&#34;&#34;Unbatches the Dataset if batched&#34;&#34;&#34;
                if self.is_batched:
                        n1d, n2d, *nd = self.data.shape
                        self.data = self.data.reshape((n1d*n2d, *nd))
                        if self.target is not None:
                                n1t, n2t, *nt = self.target.shape
                                self.target = self.target.reshape((n1t*n2t, *nt))
                return self

        def cardinality(self):
                &#34;&#34;&#34; Returns the number of data points in the dataset.&#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError

                if self.is_batched:
                        return self.data.shape[0] * self.data.shape[1]
                else:
                        return self.data.shape[0]

        def concatenate(self, ds_list):
                &#34;&#34;&#34;Concatenates this Dataset with any number of datasets.

                Args:
                        ds_list: a list of datasets to use for concatenation.
                &#34;&#34;&#34;

                if self.data is None:
                        raise UninitializedDatasetError
                for ds in ds_list:
                        if ds.data is None:
                                raise UninitializedDatasetError

                self.data = np.concatenate((self.data, *[ds.data for ds in ds_list]))
                if self.target is not None:
                        self.target = np.concatenate((self.target, *[ds.target for ds in ds_list]))
                return self

        def enumerate(self):
                &#34;&#34;&#34;Enumerates the dataset into numbered data elements.

                enables the user to do this:
                ```python
                &gt;&gt;&gt; ds.enumerate().batch(1)
                &gt;&gt;&gt; for (i, x), y in ds:
                ...     print(i, x, y)
                ```
                &#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError
                enum = []
                for i in range(self.cardinality()):
                        enum.append([i, self.data[i]])
                self.data = np.array(enum)
                return self

        def filter(self, function):
                &#34;&#34;&#34;Filters the dataset given a certain function.

                Args:
                        function: specifies a condition [function(x)] to keep each element x in the dataset.
                &#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError
                new_data = []
                for x in self.data:
                        if function(x):
                                new_data.append(x)
                self.data = np.array(new_data)
                return self

        def numpy(self):
                &#34;&#34;&#34;Returns the Dataset in a numpy format.

                Returns:
                        dataset features: if dataset is not labeled
                        dataset features, dataset labels: if dataset is labeled
                &#34;&#34;&#34;
                if self.data is None and self.target is None:
                        raise UninitializedDatasetError
                elif self.target is None:
                        return self.data
                elif self.data is None:
                        return self.target
                else:
                        return self.data, self.target

        def map(self, function):
                &#34;&#34;&#34;Maps each element in the dataset with the function map.&#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError
                function = np.vectorize(function)
                return function(self.data)

        def range(self, *args):
                &#34;&#34;&#34;Returns a new Dataset with data as a numbered list.

                uses the same syntax as np.arange()
                &#34;&#34;&#34;
                self.data = np.arange(*args)
                return self

        def shuffle(self):
                &#34;&#34;&#34;Arrays shuffled in-place by their first dimension&#34;&#34;&#34;

                if self.data is None:
                        raise UninitializedDatasetError

                # Generate random seed
                seed = np.random.randint(0, 2 ** (32 - 1) - 1)

                if self.target is not None:
                        # Shuffle both arrays in-place using the same seed
                        for array in [self.data, self.target]:
                                # Generate random state object
                                r_state = np.random.RandomState(seed)
                                r_state.shuffle(array)

                else:
                        # Generate random state object and only shuffle the data array
                        r_state = np.random.RandomState(seed)
                        r_state.shuffle(self.data)

                return self

        def split(self, split_percentage, shuffle=False):
                &#34;&#34;&#34;Splits the dataset into 2 batches (training and testing/validation)

                        Args:
                                split_percentage: (float) percentage of the testing/validation data points
                                shuffle: (bool) if true, the data is shuffled before the split

                        Returns:
                                If the dataset was initialized with x only:     returns unlabeled ds_train, ds_test
                                If the dataset was initialized with x and y: returns labeled ds_train, ds_test
                &#34;&#34;&#34;

                if self.data is None:
                        raise UninitializedDatasetError
                holdout = int(split_percentage * self.data.shape[0])
                if shuffle:
                        self.shuffle()

                x_test = self.data[holdout:]
                x_train = self.data[:holdout]

                if self.target is not None:
                        y_test = self.target[holdout:]
                        y_train = self.target[:holdout]
                else:
                        y_train = None
                        y_test = None

                return Dataset(x=x_train, y=y_train), Dataset(x=x_test, y=y_test)

        def take(self, limit):
                &#34;&#34;&#34;Takes the first N of data points in dataset to a given end.

                usefull for visulaizing the dataset as follows:
                ```python
                &gt;&gt;&gt; for x, y in ds.copy().take(5):
                ...     print(x, y)
                ```
                &#34;&#34;&#34;
                if self.data is None and self.target is None:
                        raise UninitializedDatasetError
                if self.data is not None:
                        self.data = self.data[:limit]
                if self.target is not None:
                        self.target = self.target[:limit]
                return self

        def skip(self, limit):
                &#34;&#34;&#34;a function that skips data in dataset from a given start.&#34;&#34;&#34;
                if self.data is None and self.target is None:
                        raise UninitializedDatasetError
                if self.data is not None:
                        self.data = self.data[limit:]
                if self.target is not None:
                        self.target = self.target[limit:]
                return self

        def add_data(self, x):
                &#34;&#34;&#34;Add features to a dataset.&#34;&#34;&#34;
                x = np.array(x)
                if self.target is not None:
                        if x.shape[0] != self.target.shape[0]:
                                raise UnsupportedShapeError(x.shape[0], self.target.shape[0])
                self.data = x
                return self

        def add_targets(self, y):
                &#34;&#34;&#34;add labels to a dataset.&#34;&#34;&#34;
                y = np.array(y)
                if self.data is not None:
                        if self.data.shape[0] != y.shape[0]:
                                raise UnsupportedShapeError(y.shape[0], self.data.shape[0])
                self.target = y

                return self

        def normalize(self):
                &#34;&#34;&#34;normalize the dataset so as to be centred around the origin.&#34;&#34;&#34;
                if self.data is None:
                        raise UninitializedDatasetError
                self.data = (self.data-self.data.mean(axis=0))/np.sqrt(self.data.var(axis=0)+1e-6)
                return self</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="ainshamsflow.data.ImageDataGenerator" href="#ainshamsflow.data.ImageDataGenerator">ImageDataGenerator</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="ainshamsflow.data.Dataset.__bool__"><code class="name flex">
<span>def <span class="ident">__bool__</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns True if the Dataset is not None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def __bool__(self):
        &#34;&#34;&#34;Returns True if the Dataset is not None.&#34;&#34;&#34;
        return self.data is not None</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.__iter__"><code class="name flex">
<span>def <span class="ident">__iter__</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the Dataset as an Interator.</p>
<p>Enables the user to do this:</p>
<pre><code class="python">&gt;&gt;&gt; for x, y in ds.batch(1):
...     print(x, y)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def __iter__(self):
        &#34;&#34;&#34;Defines the Dataset as an Interator.

        Enables the user to do this:
        ```python
        &gt;&gt;&gt; for x, y in ds.batch(1):
        ...     print(x, y)
        ```
        &#34;&#34;&#34;
        if self.data is None:
                raise UninitializedDatasetError

        if not self.is_batched:
                self.batch(self.cardinality())

        self.index = 0
        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.__len__"><code class="name flex">
<span>def <span class="ident">__len__</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the number of data points in the dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def __len__(self):
        &#34;&#34;&#34;Returns the number of data points in the dataset.&#34;&#34;&#34;
        return self.cardinality()</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.__next__"><code class="name flex">
<span>def <span class="ident">__next__</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the Dataset as an Interator.</p>
<p>Enables the user to do this:</p>
<pre><code class="python">&gt;&gt;&gt; for x, y in ds.batch(1):
...     print(x, y)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def __next__(self):
        &#34;&#34;&#34;Defines the Dataset as an Interator.

        Enables the user to do this:
        ```python
        &gt;&gt;&gt; for x, y in ds.batch(1):
        ...     print(x, y)
        ```
        &#34;&#34;&#34;
        if self.index &gt;= self.data.shape[0]:
                raise StopIteration

        if self.data is not None and self.target is not None:
                x = self.data[self.index]
                y = self.target[self.index]
                self.index += 1
                return x, y

        elif self.data is not None:
                x = self.data[self.index]
                self.index += 1
                return x</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.add_data"><code class="name flex">
<span>def <span class="ident">add_data</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Add features to a dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_data(self, x):
        &#34;&#34;&#34;Add features to a dataset.&#34;&#34;&#34;
        x = np.array(x)
        if self.target is not None:
                if x.shape[0] != self.target.shape[0]:
                        raise UnsupportedShapeError(x.shape[0], self.target.shape[0])
        self.data = x
        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.add_targets"><code class="name flex">
<span>def <span class="ident">add_targets</span></span>(<span>self, y)</span>
</code></dt>
<dd>
<div class="desc"><p>add labels to a dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_targets(self, y):
        &#34;&#34;&#34;add labels to a dataset.&#34;&#34;&#34;
        y = np.array(y)
        if self.data is not None:
                if self.data.shape[0] != y.shape[0]:
                        raise UnsupportedShapeError(y.shape[0], self.data.shape[0])
        self.target = y

        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.apply"><code class="name flex">
<span>def <span class="ident">apply</span></span>(<span>self, transformation)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies a transformation function to this dataset.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>transformation</code></strong></dt>
<dd>a function that applies to the dataset as a whole.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Dataset After transformation</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply(self, transformation):
        &#34;&#34;&#34;Applies a transformation function to this dataset.
        Args:
                   transformation: a function that applies to the dataset as a whole.
        Returns:
                 Dataset After transformation
        &#34;&#34;&#34;
        return transformation(self)</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.batch"><code class="name flex">
<span>def <span class="ident">batch</span></span>(<span>self, batch_size)</span>
</code></dt>
<dd>
<div class="desc"><p>Divides the dataset into equal parts of size equals batch_size.</p>
<p>If the dataset is already batched, this functions unbaches first, then baches the data
again with the new batch_size.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>batch_size</code></strong></dt>
<dd>the size of the batches</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def batch(self, batch_size):
        &#34;&#34;&#34; Divides the dataset into equal parts of size equals batch_size.

        If the dataset is already batched, this functions unbaches first, then baches the data
        again with the new batch_size.

        Args:
                batch_size: the size of the batches
        &#34;&#34;&#34;
        if self.is_batched:
                self.unbatch()

        if self.data is None:
                raise UninitializedDatasetError

        m = self.data.shape[0]
        remainder = m % batch_size

        self.take(m-remainder)

        _, *nd = self.data.shape
        _, *nt = self.target.shape
        self.data = self.data.reshape((-1, batch_size, *nd))
        self.target = self.target.reshape((-1, batch_size, *nt))

        self.is_batched = True
        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.cardinality"><code class="name flex">
<span>def <span class="ident">cardinality</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the number of data points in the dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cardinality(self):
        &#34;&#34;&#34; Returns the number of data points in the dataset.&#34;&#34;&#34;
        if self.data is None:
                raise UninitializedDatasetError

        if self.is_batched:
                return self.data.shape[0] * self.data.shape[1]
        else:
                return self.data.shape[0]</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.concatenate"><code class="name flex">
<span>def <span class="ident">concatenate</span></span>(<span>self, ds_list)</span>
</code></dt>
<dd>
<div class="desc"><p>Concatenates this Dataset with any number of datasets.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ds_list</code></strong></dt>
<dd>a list of datasets to use for concatenation.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def concatenate(self, ds_list):
        &#34;&#34;&#34;Concatenates this Dataset with any number of datasets.

        Args:
                ds_list: a list of datasets to use for concatenation.
        &#34;&#34;&#34;

        if self.data is None:
                raise UninitializedDatasetError
        for ds in ds_list:
                if ds.data is None:
                        raise UninitializedDatasetError

        self.data = np.concatenate((self.data, *[ds.data for ds in ds_list]))
        if self.target is not None:
                self.target = np.concatenate((self.target, *[ds.target for ds in ds_list]))
        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a copy of the dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(self):
        &#34;&#34;&#34; Returns a copy of the dataset.&#34;&#34;&#34;
        dataset_copy = Dataset()
        dataset_copy.data = np.copy(self.data)
        dataset_copy.target = np.copy(self.target)
        return dataset_copy</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.enumerate"><code class="name flex">
<span>def <span class="ident">enumerate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Enumerates the dataset into numbered data elements.</p>
<p>enables the user to do this:</p>
<pre><code class="python">&gt;&gt;&gt; ds.enumerate().batch(1)
&gt;&gt;&gt; for (i, x), y in ds:
...     print(i, x, y)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def enumerate(self):
        &#34;&#34;&#34;Enumerates the dataset into numbered data elements.

        enables the user to do this:
        ```python
        &gt;&gt;&gt; ds.enumerate().batch(1)
        &gt;&gt;&gt; for (i, x), y in ds:
        ...     print(i, x, y)
        ```
        &#34;&#34;&#34;
        if self.data is None:
                raise UninitializedDatasetError
        enum = []
        for i in range(self.cardinality()):
                enum.append([i, self.data[i]])
        self.data = np.array(enum)
        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>self, function)</span>
</code></dt>
<dd>
<div class="desc"><p>Filters the dataset given a certain function.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>function</code></strong></dt>
<dd>specifies a condition [function(x)] to keep each element x in the dataset.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter(self, function):
        &#34;&#34;&#34;Filters the dataset given a certain function.

        Args:
                function: specifies a condition [function(x)] to keep each element x in the dataset.
        &#34;&#34;&#34;
        if self.data is None:
                raise UninitializedDatasetError
        new_data = []
        for x in self.data:
                if function(x):
                        new_data.append(x)
        self.data = np.array(new_data)
        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.map"><code class="name flex">
<span>def <span class="ident">map</span></span>(<span>self, function)</span>
</code></dt>
<dd>
<div class="desc"><p>Maps each element in the dataset with the function map.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map(self, function):
        &#34;&#34;&#34;Maps each element in the dataset with the function map.&#34;&#34;&#34;
        if self.data is None:
                raise UninitializedDatasetError
        function = np.vectorize(function)
        return function(self.data)</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.normalize"><code class="name flex">
<span>def <span class="ident">normalize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>normalize the dataset so as to be centred around the origin.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize(self):
        &#34;&#34;&#34;normalize the dataset so as to be centred around the origin.&#34;&#34;&#34;
        if self.data is None:
                raise UninitializedDatasetError
        self.data = (self.data-self.data.mean(axis=0))/np.sqrt(self.data.var(axis=0)+1e-6)
        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.numpy"><code class="name flex">
<span>def <span class="ident">numpy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the Dataset in a numpy format.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dataset features</code></dt>
<dd>if dataset is not labeled</dd>
<dt><code>dataset features, dataset labels</code></dt>
<dd>if dataset is labeled</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def numpy(self):
        &#34;&#34;&#34;Returns the Dataset in a numpy format.

        Returns:
                dataset features: if dataset is not labeled
                dataset features, dataset labels: if dataset is labeled
        &#34;&#34;&#34;
        if self.data is None and self.target is None:
                raise UninitializedDatasetError
        elif self.target is None:
                return self.data
        elif self.data is None:
                return self.target
        else:
                return self.data, self.target</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.range"><code class="name flex">
<span>def <span class="ident">range</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a new Dataset with data as a numbered list.</p>
<p>uses the same syntax as np.arange()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def range(self, *args):
        &#34;&#34;&#34;Returns a new Dataset with data as a numbered list.

        uses the same syntax as np.arange()
        &#34;&#34;&#34;
        self.data = np.arange(*args)
        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.shuffle"><code class="name flex">
<span>def <span class="ident">shuffle</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Arrays shuffled in-place by their first dimension</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shuffle(self):
        &#34;&#34;&#34;Arrays shuffled in-place by their first dimension&#34;&#34;&#34;

        if self.data is None:
                raise UninitializedDatasetError

        # Generate random seed
        seed = np.random.randint(0, 2 ** (32 - 1) - 1)

        if self.target is not None:
                # Shuffle both arrays in-place using the same seed
                for array in [self.data, self.target]:
                        # Generate random state object
                        r_state = np.random.RandomState(seed)
                        r_state.shuffle(array)

        else:
                # Generate random state object and only shuffle the data array
                r_state = np.random.RandomState(seed)
                r_state.shuffle(self.data)

        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.skip"><code class="name flex">
<span>def <span class="ident">skip</span></span>(<span>self, limit)</span>
</code></dt>
<dd>
<div class="desc"><p>a function that skips data in dataset from a given start.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def skip(self, limit):
        &#34;&#34;&#34;a function that skips data in dataset from a given start.&#34;&#34;&#34;
        if self.data is None and self.target is None:
                raise UninitializedDatasetError
        if self.data is not None:
                self.data = self.data[limit:]
        if self.target is not None:
                self.target = self.target[limit:]
        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.split"><code class="name flex">
<span>def <span class="ident">split</span></span>(<span>self, split_percentage, shuffle=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Splits the dataset into 2 batches (training and testing/validation)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>split_percentage</code></strong></dt>
<dd>(float) percentage of the testing/validation data points</dd>
<dt><strong><code>shuffle</code></strong></dt>
<dd>(bool) if true, the data is shuffled before the split</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>If the dataset was initialized with x only</code></dt>
<dd>
<p>returns unlabeled ds_train, ds_test</p>
</dd>
<dt><code>If the dataset was initialized with x and y</code></dt>
<dd>returns labeled ds_train, ds_test</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split(self, split_percentage, shuffle=False):
        &#34;&#34;&#34;Splits the dataset into 2 batches (training and testing/validation)

                Args:
                        split_percentage: (float) percentage of the testing/validation data points
                        shuffle: (bool) if true, the data is shuffled before the split

                Returns:
                        If the dataset was initialized with x only:     returns unlabeled ds_train, ds_test
                        If the dataset was initialized with x and y: returns labeled ds_train, ds_test
        &#34;&#34;&#34;

        if self.data is None:
                raise UninitializedDatasetError
        holdout = int(split_percentage * self.data.shape[0])
        if shuffle:
                self.shuffle()

        x_test = self.data[holdout:]
        x_train = self.data[:holdout]

        if self.target is not None:
                y_test = self.target[holdout:]
                y_train = self.target[:holdout]
        else:
                y_train = None
                y_test = None

        return Dataset(x=x_train, y=y_train), Dataset(x=x_test, y=y_test)</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.take"><code class="name flex">
<span>def <span class="ident">take</span></span>(<span>self, limit)</span>
</code></dt>
<dd>
<div class="desc"><p>Takes the first N of data points in dataset to a given end.</p>
<p>usefull for visulaizing the dataset as follows:</p>
<pre><code class="python">&gt;&gt;&gt; for x, y in ds.copy().take(5):
...     print(x, y)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def take(self, limit):
        &#34;&#34;&#34;Takes the first N of data points in dataset to a given end.

        usefull for visulaizing the dataset as follows:
        ```python
        &gt;&gt;&gt; for x, y in ds.copy().take(5):
        ...     print(x, y)
        ```
        &#34;&#34;&#34;
        if self.data is None and self.target is None:
                raise UninitializedDatasetError
        if self.data is not None:
                self.data = self.data[:limit]
        if self.target is not None:
                self.target = self.target[:limit]
        return self</code></pre>
</details>
</dd>
<dt id="ainshamsflow.data.Dataset.unbatch"><code class="name flex">
<span>def <span class="ident">unbatch</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Unbatches the Dataset if batched</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def unbatch(self):
        &#34;&#34;&#34;Unbatches the Dataset if batched&#34;&#34;&#34;
        if self.is_batched:
                n1d, n2d, *nd = self.data.shape
                self.data = self.data.reshape((n1d*n2d, *nd))
                if self.target is not None:
                        n1t, n2t, *nt = self.target.shape
                        self.target = self.target.reshape((n1t*n2t, *nt))
        return self</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="ainshamsflow.data.ImageDataGenerator"><code class="flex name class">
<span>class <span class="ident">ImageDataGenerator</span></span>
</code></dt>
<dd>
<div class="desc"><p>Image Data Generator Class.</p>
<p>This class helps in training large amounts of images with minimal memory allocation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ImageDataGenerator(Dataset):
        &#34;&#34;&#34;Image Data Generator Class.

        This class helps in training large amounts of images with minimal memory allocation.
        &#34;&#34;&#34;
        def __init__(self):
                self.class_name = []
                self.dir = None
                super().__init__()

        def flow_from_directory(self, directory):
                &#34;&#34;&#34;Reads Images from a Directory.

                Args:
                        directory: If directory holds images only, this function will use these images as a dataset without any labels.
                                Otherwise, if the directory holds folders of images, it will store the folder names as class names in
                                the class_names attribute. It will then label the images according to their folders.
                &#34;&#34;&#34;
                self.dir = directory
                self.class_name = [name for name in os.listdir(directory)
                                                   if os.path.isdir(os.path.join(directory, name))]
                if class_name:
                        images = []
                        labels = []
                        for i in range(len(self.class_name)):
                                for img_name in os.listdir(self.class_name[i]):
                                        if os.path.isfile(os.path.join(directory, self.class_name[i], img_name)):
                                                images.append(img_name)
                                                labels.append(i)
                        self.data = np.array(images)
                        self.target = np.array(labels)
                else:
                        images = [img_name for img_name in os.listdir(directory)
                                           if os.path.isfile(os.path.join(directory, img_name))]
                        self.data = np.array(images)

                self.shuffle()
                return self

        def __next__(self):
                &#34;&#34;&#34;Defines the ImageDataGenerator as an Interator.

                Enables the user to do this:
                ```python
                &gt;&gt;&gt; for x, y in ds.batch(1):
                ...     print(x, y)
                ```
                &#34;&#34;&#34;
                if self.index &gt;= self.data.shape[0]:
                        raise StopIteration
                self.index += 1
                img = self._extract_img(self.data[self.index-1], self.target[self.index-1])
                if self.target is not None:
                        label = self.target[self.index-1]
                        return img, label
                else:
                        return img

        def _extract_img(self, filename, label):
                if isinstance(filename, str):
                        ans = mpimg.imread(os.path.join(self.dir, self.class_name[label], filename))
                else:
                        ans = []
                        for file, lab in zip(filename, label):
                                ans.append(self._extract_img(file, lab))
                        ans = np.array(ans)
                return ans
        
        def copy(self):
                &#34;&#34;&#34;Returns a copy of the dataset.&#34;&#34;&#34;
                dataset_copy = ImageDataGenerator()
                dataset_copy.data = np.copy(self.data)
                dataset_copy.target = np.copy(self.target)
                dataset_copy.dir = self.dir
                dataset_copy.class_name = self.class_name[:]
                return dataset_copy
        
        def split(self, split_percentage, shuffle=False):
                &#34;&#34;&#34;Splits the dataset into 2 batches (training and testing/validation)

                        Args:
                                split_percentage: (float) percentage of the testing/validation data points
                                shuffle: (bool) if true, the data is shuffled before the split

                        Returns:
                                If the dataset was initialized with x only:     returns unlabeled ds_train, ds_test
                                If the dataset was initialized with x and y: returns labeled ds_train, ds_test
                &#34;&#34;&#34;

                if self.data is None:
                        raise UninitializedDatasetError
                img_gen_train = ImageDataGenerator()
                img_gen_test = ImageDataGenerator()
                
                img_gen_train.dir = img_gen_test.dir = self.dir
                img_gen_train.class_name = self.class_name[:]
                img_gen_test.class_name = self.class_name[:]
                
                holdout = int(split_percentage * self.data.shape[0])
                if shuffle:
                        self.shuffle()

                img_gen_train.data = self.data[:holdout]
                img_gen_test.data = self.data[holdout:]

                if self.target is not None:
                        img_gen_train.target = self.target[:holdout]
                        img_gen_test.target = self.target[holdout:]

                return img_gen_train, img_gen_test</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="ainshamsflow.data.Dataset" href="#ainshamsflow.data.Dataset">Dataset</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="ainshamsflow.data.ImageDataGenerator.flow_from_directory"><code class="name flex">
<span>def <span class="ident">flow_from_directory</span></span>(<span>self, directory)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads Images from a Directory.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>directory</code></strong></dt>
<dd>If directory holds images only, this function will use these images as a dataset without any labels.
Otherwise, if the directory holds folders of images, it will store the folder names as class names in
the class_names attribute. It will then label the images according to their folders.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def flow_from_directory(self, directory):
        &#34;&#34;&#34;Reads Images from a Directory.

        Args:
                directory: If directory holds images only, this function will use these images as a dataset without any labels.
                        Otherwise, if the directory holds folders of images, it will store the folder names as class names in
                        the class_names attribute. It will then label the images according to their folders.
        &#34;&#34;&#34;
        self.dir = directory
        self.class_name = [name for name in os.listdir(directory)
                                           if os.path.isdir(os.path.join(directory, name))]
        if class_name:
                images = []
                labels = []
                for i in range(len(self.class_name)):
                        for img_name in os.listdir(self.class_name[i]):
                                if os.path.isfile(os.path.join(directory, self.class_name[i], img_name)):
                                        images.append(img_name)
                                        labels.append(i)
                self.data = np.array(images)
                self.target = np.array(labels)
        else:
                images = [img_name for img_name in os.listdir(directory)
                                   if os.path.isfile(os.path.join(directory, img_name))]
                self.data = np.array(images)

        self.shuffle()
        return self</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="ainshamsflow.data.Dataset" href="#ainshamsflow.data.Dataset">Dataset</a></b></code>:
<ul class="hlist">
<li><code><a title="ainshamsflow.data.Dataset.__bool__" href="#ainshamsflow.data.Dataset.__bool__">__bool__</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.__iter__" href="#ainshamsflow.data.Dataset.__iter__">__iter__</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.__len__" href="#ainshamsflow.data.Dataset.__len__">__len__</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.__next__" href="#ainshamsflow.data.Dataset.__next__">__next__</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.add_data" href="#ainshamsflow.data.Dataset.add_data">add_data</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.add_targets" href="#ainshamsflow.data.Dataset.add_targets">add_targets</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.apply" href="#ainshamsflow.data.Dataset.apply">apply</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.batch" href="#ainshamsflow.data.Dataset.batch">batch</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.cardinality" href="#ainshamsflow.data.Dataset.cardinality">cardinality</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.concatenate" href="#ainshamsflow.data.Dataset.concatenate">concatenate</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.copy" href="#ainshamsflow.data.Dataset.copy">copy</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.enumerate" href="#ainshamsflow.data.Dataset.enumerate">enumerate</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.filter" href="#ainshamsflow.data.Dataset.filter">filter</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.map" href="#ainshamsflow.data.Dataset.map">map</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.normalize" href="#ainshamsflow.data.Dataset.normalize">normalize</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.numpy" href="#ainshamsflow.data.Dataset.numpy">numpy</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.range" href="#ainshamsflow.data.Dataset.range">range</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.shuffle" href="#ainshamsflow.data.Dataset.shuffle">shuffle</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.skip" href="#ainshamsflow.data.Dataset.skip">skip</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.split" href="#ainshamsflow.data.Dataset.split">split</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.take" href="#ainshamsflow.data.Dataset.take">take</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.unbatch" href="#ainshamsflow.data.Dataset.unbatch">unbatch</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ainshamsflow" href="index.html">ainshamsflow</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ainshamsflow.data.Dataset" href="#ainshamsflow.data.Dataset">Dataset</a></code></h4>
<ul class="two-column">
<li><code><a title="ainshamsflow.data.Dataset.__bool__" href="#ainshamsflow.data.Dataset.__bool__">__bool__</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.__iter__" href="#ainshamsflow.data.Dataset.__iter__">__iter__</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.__len__" href="#ainshamsflow.data.Dataset.__len__">__len__</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.__next__" href="#ainshamsflow.data.Dataset.__next__">__next__</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.add_data" href="#ainshamsflow.data.Dataset.add_data">add_data</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.add_targets" href="#ainshamsflow.data.Dataset.add_targets">add_targets</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.apply" href="#ainshamsflow.data.Dataset.apply">apply</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.batch" href="#ainshamsflow.data.Dataset.batch">batch</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.cardinality" href="#ainshamsflow.data.Dataset.cardinality">cardinality</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.concatenate" href="#ainshamsflow.data.Dataset.concatenate">concatenate</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.copy" href="#ainshamsflow.data.Dataset.copy">copy</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.enumerate" href="#ainshamsflow.data.Dataset.enumerate">enumerate</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.filter" href="#ainshamsflow.data.Dataset.filter">filter</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.map" href="#ainshamsflow.data.Dataset.map">map</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.normalize" href="#ainshamsflow.data.Dataset.normalize">normalize</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.numpy" href="#ainshamsflow.data.Dataset.numpy">numpy</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.range" href="#ainshamsflow.data.Dataset.range">range</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.shuffle" href="#ainshamsflow.data.Dataset.shuffle">shuffle</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.skip" href="#ainshamsflow.data.Dataset.skip">skip</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.split" href="#ainshamsflow.data.Dataset.split">split</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.take" href="#ainshamsflow.data.Dataset.take">take</a></code></li>
<li><code><a title="ainshamsflow.data.Dataset.unbatch" href="#ainshamsflow.data.Dataset.unbatch">unbatch</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="ainshamsflow.data.ImageDataGenerator" href="#ainshamsflow.data.ImageDataGenerator">ImageDataGenerator</a></code></h4>
<ul class="">
<li><code><a title="ainshamsflow.data.ImageDataGenerator.flow_from_directory" href="#ainshamsflow.data.ImageDataGenerator.flow_from_directory">flow_from_directory</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>